{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tcn\n",
      "  Downloading keras_tcn-3.5.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras-tcn) (1.26.4)\n",
      "Collecting tensorflow (from keras-tcn)\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow->keras-tcn)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow->keras-tcn)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow->keras-tcn)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow->keras-tcn)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow->keras-tcn)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow->keras-tcn)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->keras-tcn)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow->keras-tcn)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow->keras-tcn) (1.71.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow->keras-tcn)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow->keras-tcn)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow->keras-tcn)\n",
      "  Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow->keras-tcn)\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow->keras-tcn)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.45.1)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow->keras-tcn) (14.0.0)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow->keras-tcn)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow->keras-tcn)\n",
      "  Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow->keras-tcn) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow->keras-tcn) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow->keras-tcn) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow->keras-tcn) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->keras-tcn) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow->keras-tcn) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow->keras-tcn) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->keras-tcn) (0.1.2)\n",
      "Downloading keras_tcn-3.5.6-py3-none-any.whl (12 kB)\n",
      "Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m148.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m161.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, optree, opt-einsum, ml-dtypes, h5py, google-pasta, gast, astunparse, tensorboard, keras, tensorflow, keras-tcn\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.13.0 keras-3.9.2 keras-tcn-3.5.6 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TCN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from joblib import dump\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../../../Split Data/Training Dataset/X_train #2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_train = pd.read_csv(\"../../../Split Data/Training Dataset/y_train #2.csv\", index_col=0)\n",
    "X_val = pd.read_csv(\"../../../Split Data/Validation Dataset/X_val #2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_val = pd.read_csv(\"../../../Split Data/Validation Dataset/y_val #2.csv\", index_col=0)\n",
    "X_test = pd.read_csv(\"../../../Split Data/Testing Dataset/X_test #2.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "y_test = pd.read_csv(\"../../../Split Data/Testing Dataset/y_test #2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_val_scaled = scaler.transform(X_val)   \n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "joblib.dump(scaler, \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_scaled).reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)  \n",
    "X_val = np.array(X_val_scaled).reshape(X_val_scaled.shape[0], X_val_scaled.shape[1], 1)  \n",
    "X_test = np.array(X_test_scaled).reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2   \n",
    "kernel_size = 5\n",
    "dilations = [4, 8, 16, 32, 64] \n",
    "max_len = X_train.shape[1] \n",
    "dropout_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(max_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn = TCN(\n",
    "    nb_filters= 128,\n",
    "    nb_stacks = 2,\n",
    "    kernel_size=kernel_size,\n",
    "    dilations=dilations,\n",
    "    dropout_rate=dropout_rate,\n",
    "    use_layer_norm=True,\n",
    "    return_sequences = True\n",
    ")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling = GlobalMaxPooling1D()(tcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pooling = GlobalAveragePooling1D()(tcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = Concatenate()([max_pooling, avg_pooling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(64, activation= 'relu')(pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1 = Dropout(0.2)(dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Dense(2, activation='softmax')(dropout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    p = true_positives / (predicted_positives + K.epsilon())\n",
    "    r = true_positives / (possible_positives + K.epsilon())\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 15, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " tcn_2 (TCN)                 (None, 15, 128)              1565056   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 128)                  0         ['tcn_2[0][0]']               \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['tcn_2[0][0]']               \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256)                  0         ['global_max_pooling1d_1[0][0]\n",
      " )                                                                  ',                            \n",
      "                                                                     'global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   16448     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    130       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1581634 (6.03 MB)\n",
      "Trainable params: 1581634 (6.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate = 0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', f1]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (8001, 2)\n",
      "y_val shape: (1714, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/251 [..............................] - ETA: 11s - loss: 0.3662 - accuracy: 0.8125 - f1: 0.8125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9100 - f1: 0.9104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 10s 38ms/step - loss: 0.2410 - accuracy: 0.9100 - f1: 0.9104 - val_loss: 0.2837 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 2/100\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.2397 - accuracy: 0.9116 - f1: 0.9120 - val_loss: 0.2723 - val_accuracy: 0.9067 - val_f1: 0.9065\n",
      "Epoch 3/100\n",
      "251/251 [==============================] - 9s 37ms/step - loss: 0.2336 - accuracy: 0.9124 - f1: 0.9127 - val_loss: 0.2798 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 4/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2378 - accuracy: 0.9126 - f1: 0.9130 - val_loss: 0.2684 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 5/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2367 - accuracy: 0.9124 - f1: 0.9127 - val_loss: 0.3030 - val_accuracy: 0.9026 - val_f1: 0.9025\n",
      "Epoch 6/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2368 - accuracy: 0.9146 - f1: 0.9150 - val_loss: 0.2718 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 7/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2381 - accuracy: 0.9078 - f1: 0.9081 - val_loss: 0.2595 - val_accuracy: 0.9067 - val_f1: 0.9065\n",
      "Epoch 8/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2312 - accuracy: 0.9143 - f1: 0.9146 - val_loss: 0.2696 - val_accuracy: 0.9078 - val_f1: 0.9077\n",
      "Epoch 9/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2289 - accuracy: 0.9125 - f1: 0.9128 - val_loss: 0.2734 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 10/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2349 - accuracy: 0.9134 - f1: 0.9137 - val_loss: 0.2777 - val_accuracy: 0.8991 - val_f1: 0.8990\n",
      "Epoch 11/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2323 - accuracy: 0.9121 - f1: 0.9125 - val_loss: 0.2710 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 12/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2312 - accuracy: 0.9166 - f1: 0.9170 - val_loss: 0.2939 - val_accuracy: 0.8985 - val_f1: 0.8980\n",
      "Epoch 13/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2333 - accuracy: 0.9100 - f1: 0.9104 - val_loss: 0.2744 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 14/100\n",
      "251/251 [==============================] - 9s 37ms/step - loss: 0.2359 - accuracy: 0.9131 - f1: 0.9135 - val_loss: 0.2723 - val_accuracy: 0.9090 - val_f1: 0.9088\n",
      "Epoch 15/100\n",
      "251/251 [==============================] - 9s 34ms/step - loss: 0.2293 - accuracy: 0.9125 - f1: 0.9128 - val_loss: 0.2856 - val_accuracy: 0.9020 - val_f1: 0.9019\n",
      "Epoch 16/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2298 - accuracy: 0.9125 - f1: 0.9128 - val_loss: 0.2859 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 17/100\n",
      "251/251 [==============================] - 9s 34ms/step - loss: 0.2290 - accuracy: 0.9143 - f1: 0.9107 - val_loss: 0.2791 - val_accuracy: 0.9014 - val_f1: 0.9013\n",
      "Epoch 18/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2361 - accuracy: 0.9141 - f1: 0.9145 - val_loss: 0.2764 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 19/100\n",
      "251/251 [==============================] - 9s 34ms/step - loss: 0.2309 - accuracy: 0.9154 - f1: 0.9157 - val_loss: 0.2739 - val_accuracy: 0.8985 - val_f1: 0.8984\n",
      "Epoch 20/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2261 - accuracy: 0.9154 - f1: 0.9157 - val_loss: 0.2749 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 21/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2274 - accuracy: 0.9149 - f1: 0.9152 - val_loss: 0.2764 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 22/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2229 - accuracy: 0.9150 - f1: 0.9153 - val_loss: 0.2731 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 23/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2263 - accuracy: 0.9146 - f1: 0.9150 - val_loss: 0.2911 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 24/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2225 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 0.2752 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 25/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2252 - accuracy: 0.9149 - f1: 0.9152 - val_loss: 0.2853 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 26/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2286 - accuracy: 0.9161 - f1: 0.9165 - val_loss: 0.2755 - val_accuracy: 0.9061 - val_f1: 0.9055\n",
      "Epoch 27/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2263 - accuracy: 0.9156 - f1: 0.9160 - val_loss: 0.2692 - val_accuracy: 0.8985 - val_f1: 0.8984\n",
      "Epoch 28/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2252 - accuracy: 0.9153 - f1: 0.9156 - val_loss: 0.2851 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 29/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2231 - accuracy: 0.9158 - f1: 0.9161 - val_loss: 0.2730 - val_accuracy: 0.9067 - val_f1: 0.9065\n",
      "Epoch 30/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2241 - accuracy: 0.9129 - f1: 0.9132 - val_loss: 0.2938 - val_accuracy: 0.8932 - val_f1: 0.8932\n",
      "Epoch 31/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2263 - accuracy: 0.9156 - f1: 0.9121 - val_loss: 0.2806 - val_accuracy: 0.9026 - val_f1: 0.9025\n",
      "Epoch 32/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2338 - accuracy: 0.9100 - f1: 0.9104 - val_loss: 0.2795 - val_accuracy: 0.9067 - val_f1: 0.9065\n",
      "Epoch 33/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2240 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 0.2854 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 34/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2219 - accuracy: 0.9164 - f1: 0.9167 - val_loss: 0.2750 - val_accuracy: 0.9020 - val_f1: 0.9019\n",
      "Epoch 35/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2204 - accuracy: 0.9153 - f1: 0.9156 - val_loss: 0.2722 - val_accuracy: 0.9020 - val_f1: 0.9019\n",
      "Epoch 36/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2227 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 0.2758 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 37/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2218 - accuracy: 0.9153 - f1: 0.9117 - val_loss: 0.2784 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 38/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2182 - accuracy: 0.9149 - f1: 0.9152 - val_loss: 0.2858 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 39/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2209 - accuracy: 0.9166 - f1: 0.9170 - val_loss: 0.2784 - val_accuracy: 0.8991 - val_f1: 0.8990\n",
      "Epoch 40/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2204 - accuracy: 0.9193 - f1: 0.9196 - val_loss: 0.2820 - val_accuracy: 0.8985 - val_f1: 0.8984\n",
      "Epoch 41/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2172 - accuracy: 0.9176 - f1: 0.9180 - val_loss: 0.2789 - val_accuracy: 0.8991 - val_f1: 0.8990\n",
      "Epoch 42/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2226 - accuracy: 0.9176 - f1: 0.9180 - val_loss: 0.2838 - val_accuracy: 0.8944 - val_f1: 0.8944\n",
      "Epoch 43/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2273 - accuracy: 0.9161 - f1: 0.9165 - val_loss: 0.2875 - val_accuracy: 0.8973 - val_f1: 0.8972\n",
      "Epoch 44/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2194 - accuracy: 0.9161 - f1: 0.9165 - val_loss: 0.2805 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 45/100\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.2135 - accuracy: 0.9159 - f1: 0.9162 - val_loss: 0.2722 - val_accuracy: 0.9096 - val_f1: 0.9094\n",
      "Epoch 46/100\n",
      "251/251 [==============================] - 9s 34ms/step - loss: 0.2163 - accuracy: 0.9168 - f1: 0.9171 - val_loss: 0.2819 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 47/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2188 - accuracy: 0.9176 - f1: 0.9180 - val_loss: 0.2741 - val_accuracy: 0.9026 - val_f1: 0.9025\n",
      "Epoch 48/100\n",
      "251/251 [==============================] - 9s 34ms/step - loss: 0.2165 - accuracy: 0.9179 - f1: 0.9182 - val_loss: 0.2868 - val_accuracy: 0.8915 - val_f1: 0.8915\n",
      "Epoch 49/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2192 - accuracy: 0.9164 - f1: 0.9167 - val_loss: 0.2953 - val_accuracy: 0.8944 - val_f1: 0.8939\n",
      "Epoch 50/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2178 - accuracy: 0.9180 - f1: 0.9183 - val_loss: 0.2699 - val_accuracy: 0.9072 - val_f1: 0.9071\n",
      "Epoch 51/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2164 - accuracy: 0.9179 - f1: 0.9182 - val_loss: 0.2820 - val_accuracy: 0.9014 - val_f1: 0.9013\n",
      "Epoch 52/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2168 - accuracy: 0.9196 - f1: 0.9161 - val_loss: 0.2922 - val_accuracy: 0.9002 - val_f1: 0.9001\n",
      "Epoch 53/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2160 - accuracy: 0.9195 - f1: 0.9198 - val_loss: 0.2907 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 54/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2130 - accuracy: 0.9186 - f1: 0.9189 - val_loss: 0.2779 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 55/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2156 - accuracy: 0.9204 - f1: 0.9207 - val_loss: 0.3043 - val_accuracy: 0.8991 - val_f1: 0.8990\n",
      "Epoch 56/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2196 - accuracy: 0.9163 - f1: 0.9166 - val_loss: 0.2836 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 57/100\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.2141 - accuracy: 0.9193 - f1: 0.9196 - val_loss: 0.2879 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 58/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2090 - accuracy: 0.9213 - f1: 0.9216 - val_loss: 0.2949 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 59/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2136 - accuracy: 0.9195 - f1: 0.9198 - val_loss: 0.3093 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 60/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2154 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 0.2910 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 61/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2149 - accuracy: 0.9175 - f1: 0.9178 - val_loss: 0.2931 - val_accuracy: 0.9020 - val_f1: 0.9019\n",
      "Epoch 62/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2143 - accuracy: 0.9183 - f1: 0.9186 - val_loss: 0.2874 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 63/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2150 - accuracy: 0.9186 - f1: 0.9151 - val_loss: 0.2913 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 64/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2277 - accuracy: 0.9169 - f1: 0.9172 - val_loss: 0.2845 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 65/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2073 - accuracy: 0.9216 - f1: 0.9219 - val_loss: 0.2872 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 66/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2102 - accuracy: 0.9198 - f1: 0.9201 - val_loss: 0.2975 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 67/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2127 - accuracy: 0.9219 - f1: 0.9183 - val_loss: 0.2870 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 68/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2313 - accuracy: 0.9199 - f1: 0.9202 - val_loss: 0.2921 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 69/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2105 - accuracy: 0.9193 - f1: 0.9196 - val_loss: 0.2859 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 70/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2122 - accuracy: 0.9179 - f1: 0.9182 - val_loss: 0.3049 - val_accuracy: 0.9072 - val_f1: 0.9071\n",
      "Epoch 71/100\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.2114 - accuracy: 0.9193 - f1: 0.9157 - val_loss: 0.2882 - val_accuracy: 0.9026 - val_f1: 0.9025\n",
      "Epoch 72/100\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.2072 - accuracy: 0.9210 - f1: 0.9213 - val_loss: 0.2928 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 73/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2081 - accuracy: 0.9200 - f1: 0.9203 - val_loss: 0.2959 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 74/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2100 - accuracy: 0.9193 - f1: 0.9196 - val_loss: 0.2946 - val_accuracy: 0.9037 - val_f1: 0.9036\n",
      "Epoch 75/100\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.2023 - accuracy: 0.9233 - f1: 0.9197 - val_loss: 0.2921 - val_accuracy: 0.9014 - val_f1: 0.9013\n",
      "Epoch 76/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2066 - accuracy: 0.9198 - f1: 0.9201 - val_loss: 0.2816 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 77/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2042 - accuracy: 0.9205 - f1: 0.9208 - val_loss: 0.3000 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 78/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2089 - accuracy: 0.9206 - f1: 0.9209 - val_loss: 0.2972 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2079 - accuracy: 0.9228 - f1: 0.9231 - val_loss: 0.2942 - val_accuracy: 0.9020 - val_f1: 0.9019\n",
      "Epoch 80/100\n",
      "251/251 [==============================] - 8s 34ms/step - loss: 0.2065 - accuracy: 0.9195 - f1: 0.9198 - val_loss: 0.2992 - val_accuracy: 0.9072 - val_f1: 0.9071\n",
      "Epoch 81/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2078 - accuracy: 0.9199 - f1: 0.9202 - val_loss: 0.2995 - val_accuracy: 0.9061 - val_f1: 0.9059\n",
      "Epoch 82/100\n",
      "251/251 [==============================] - 8s 34ms/step - loss: 0.2038 - accuracy: 0.9204 - f1: 0.9207 - val_loss: 0.2881 - val_accuracy: 0.9113 - val_f1: 0.9111\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - 8s 34ms/step - loss: 0.2068 - accuracy: 0.9229 - f1: 0.9232 - val_loss: 0.3160 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 84/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.1990 - accuracy: 0.9220 - f1: 0.9223 - val_loss: 0.3338 - val_accuracy: 0.8856 - val_f1: 0.8857\n",
      "Epoch 85/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2055 - accuracy: 0.9235 - f1: 0.9238 - val_loss: 0.2948 - val_accuracy: 0.9078 - val_f1: 0.9077\n",
      "Epoch 86/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2057 - accuracy: 0.9235 - f1: 0.9238 - val_loss: 0.3087 - val_accuracy: 0.9049 - val_f1: 0.9048\n",
      "Epoch 87/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2036 - accuracy: 0.9220 - f1: 0.9223 - val_loss: 0.2992 - val_accuracy: 0.9008 - val_f1: 0.9007\n",
      "Epoch 88/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2026 - accuracy: 0.9210 - f1: 0.9213 - val_loss: 0.3171 - val_accuracy: 0.9008 - val_f1: 0.9007\n",
      "Epoch 89/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2036 - accuracy: 0.9225 - f1: 0.9228 - val_loss: 0.3095 - val_accuracy: 0.9067 - val_f1: 0.9065\n",
      "Epoch 90/100\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.2034 - accuracy: 0.9215 - f1: 0.9218 - val_loss: 0.3266 - val_accuracy: 0.8991 - val_f1: 0.8990\n",
      "Epoch 91/100\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.2011 - accuracy: 0.9198 - f1: 0.9201 - val_loss: 0.2977 - val_accuracy: 0.9084 - val_f1: 0.9082\n",
      "Epoch 92/100\n",
      "251/251 [==============================] - 8s 33ms/step - loss: 0.2022 - accuracy: 0.9218 - f1: 0.9221 - val_loss: 0.2999 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 93/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2015 - accuracy: 0.9219 - f1: 0.9222 - val_loss: 0.3007 - val_accuracy: 0.9055 - val_f1: 0.9053\n",
      "Epoch 94/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2014 - accuracy: 0.9208 - f1: 0.9211 - val_loss: 0.3142 - val_accuracy: 0.9008 - val_f1: 0.9007\n",
      "Epoch 95/100\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.2015 - accuracy: 0.9233 - f1: 0.9236 - val_loss: 0.3099 - val_accuracy: 0.9032 - val_f1: 0.9030\n",
      "Epoch 96/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2035 - accuracy: 0.9224 - f1: 0.9227 - val_loss: 0.3030 - val_accuracy: 0.9096 - val_f1: 0.9094\n",
      "Epoch 97/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2003 - accuracy: 0.9225 - f1: 0.9228 - val_loss: 0.3090 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 98/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2000 - accuracy: 0.9238 - f1: 0.9241 - val_loss: 0.3115 - val_accuracy: 0.9043 - val_f1: 0.9042\n",
      "Epoch 99/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.1998 - accuracy: 0.9244 - f1: 0.9247 - val_loss: 0.3125 - val_accuracy: 0.8996 - val_f1: 0.8996\n",
      "Epoch 100/100\n",
      "251/251 [==============================] - 8s 31ms/step - loss: 0.2009 - accuracy: 0.9243 - f1: 0.9246 - val_loss: 0.3165 - val_accuracy: 0.9067 - val_f1: 0.9065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_val, y_val), verbose = 1, \n",
    "          callbacks = \n",
    "          ModelCheckpoint(filepath=\"TCN #2.h5\", \n",
    "          monitor='val_f1', mode='max',save_best_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 14:50:08.468290: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #0 (named tcn_2)for weight tcn_2/residual_block_0/conv1D_0/kernel. Weight expects shape (5, 1, 128). Received saved weight with shape (128,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m TCN_model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTCN #2.h5\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/saving/saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:138\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile)\u001b[39m\n\u001b[32m    133\u001b[39m     model = saving_utils.model_from_config(\n\u001b[32m    134\u001b[39m         model_config, custom_objects=custom_objects\n\u001b[32m    135\u001b[39m     )\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[43mload_weights_from_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_weights\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m:\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# instantiate optimizer\u001b[39;00m\n\u001b[32m    142\u001b[39m     training_config = f.attrs.get(\u001b[33m\"\u001b[39m\u001b[33mtraining_config\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:375\u001b[39m, in \u001b[36mload_weights_from_hdf5_group\u001b[39m\u001b[34m(f, model)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weight_values) != \u001b[38;5;28mlen\u001b[39m(symbolic_weights):\n\u001b[32m    369\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    370\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeight count mismatch for layer #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe current model, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in the save file). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    372\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLayer expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(symbolic_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m weight(s). Received \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    373\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weight_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m saved weight(s)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    374\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[43m_set_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43msymbolic_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer #\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m (named \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtop_level_model_weights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m    383\u001b[39m     symbolic_weights = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    384\u001b[39m         \u001b[38;5;66;03m# model.weights\u001b[39;00m\n\u001b[32m    385\u001b[39m         v\n\u001b[32m    386\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m model._trainable_variables + model._non_trainable_variables\n\u001b[32m    387\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m model.weights\n\u001b[32m    388\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:440\u001b[39m, in \u001b[36m_set_weights\u001b[39m\u001b[34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[39m\n\u001b[32m    430\u001b[39m             warnings.warn(\n\u001b[32m    431\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdue to mismatch in shape for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    437\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    438\u001b[39m             )\n\u001b[32m    439\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    441\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    442\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i].path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    443\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    444\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived saved weight \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    445\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m         )\n\u001b[32m    447\u001b[39m     symbolic_weights[i].assign(weight_value)\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33mfinalize_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[31mValueError\u001b[39m: Shape mismatch in layer #0 (named tcn_2)for weight tcn_2/residual_block_0/conv1D_0/kernel. Weight expects shape (5, 1, 128). Received saved weight with shape (128,)"
     ]
    }
   ],
   "source": [
    "TCN_model = load_model('TCN #2.h5', custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 17ms/step - loss: 0.3120 - accuracy: 0.8968 - f1: 0.8968\n"
     ]
    }
   ],
   "source": [
    "results = TCN_model.evaluate(X_test, y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = TCN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.argmax(axis=1)\n",
    "y_pred = y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7563e4397070>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "matrix = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"benign\", \"phishing\"])                            \n",
    "matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "Precision = metrics.precision_score(y_test, y_pred)\n",
    "Recall = metrics.recall_score(y_test, y_pred)\n",
    "F1_score = metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.8967930029154519, 'Precision': 0.9151943462897526, 'Recall': 0.8809523809523809, 'F1_score': 0.8977469670710573}\n"
     ]
    }
   ],
   "source": [
    "print({\"Accuracy\":Accuracy,\"Precision\":Precision,\"Recall\":Recall,\"F1_score\":F1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Metrics of Dataset #2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({\"Model\": \"TCN\", \"Accuracy\": [Accuracy], \"Precision\":[Precision], \"Recall\": [Recall], \"F1_score\": [F1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.869388</td>\n",
       "      <td>0.859170</td>\n",
       "      <td>0.892290</td>\n",
       "      <td>0.875417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.900875</td>\n",
       "      <td>0.913953</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.902411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.898649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.896210</td>\n",
       "      <td>0.893736</td>\n",
       "      <td>0.905896</td>\n",
       "      <td>0.899775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCN</td>\n",
       "      <td>0.896793</td>\n",
       "      <td>0.915194</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.897747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    Recall  F1_score\n",
       "0      LinearSVC  0.869388   0.859170  0.892290  0.875417\n",
       "1  Random Forest  0.900875   0.913953  0.891156  0.902411\n",
       "2        XGBoost  0.895044   0.892617  0.904762  0.898649\n",
       "3            MLP  0.896210   0.893736  0.905896  0.899775\n",
       "4            TCN  0.896793   0.915194  0.880952  0.897747"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Metrics of Dataset #2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
